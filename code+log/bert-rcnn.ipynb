{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1472453,"sourceType":"datasetVersion","datasetId":863934}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport transformers\nimport pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\"\n\ntrain_df = pd.read_csv(path, encoding='latin1')\ntrain_df.Sentiment.replace(to_replace='Extremely Positive', value='Positive',inplace=True)\ntrain_df.Sentiment.replace(to_replace='Extremely Negative', value='Negative',inplace=True)\nprint(train_df.Sentiment.value_counts())\ncorona_train = train_df[['OriginalTweet','Sentiment']]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T03:37:59.175240Z","iopub.execute_input":"2024-01-10T03:37:59.176444Z","iopub.status.idle":"2024-01-10T03:38:04.461246Z","shell.execute_reply.started":"2024-01-10T03:37:59.176393Z","shell.execute_reply":"2024-01-10T03:38:04.460221Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Sentiment\nPositive    18046\nNegative    15398\nNeutral      7713\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport random\n\ndef process_text(text):\n    text = text.lower()\n    text = re.sub(\"https*\\S+\", \"[ URL ]\", text)\n    # remove extra spaces\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\s{2,}',' ', text)\n    text = re.sub('[^a-zA-Z\\s]', '', text)\n    return text\n\ndef set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_seed(114514)\ncorona_train.OriginalTweet = corona_train.OriginalTweet.apply(process_text)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-10T03:38:07.045314Z","iopub.execute_input":"2024-01-10T03:38:07.046189Z","iopub.status.idle":"2024-01-10T03:38:07.962272Z","shell.execute_reply.started":"2024-01-10T03:38:07.046152Z","shell.execute_reply":"2024-01-10T03:38:07.961282Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/3125746849.py:24: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  corona_train.OriginalTweet = corona_train.OriginalTweet.apply(process_text)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_list = []\ntest_list = []\n\ntext_id = 'OriginalTweet'\ntarget_id = 'Sentiment'\n# Print unique values in the 'Sentiment' column\nunique_values = corona_train[target_id].unique()\nprint(\"Unique values in 'Sentiment' column:\", unique_values)\n\n# Create a dictionary mapping each unique value to an index\nresult_dict = {value: index for index, value in enumerate(unique_values, 0)}\nprint(\"Resulting dictionary:\", result_dict)\n\n\ndef get_list(train_df):\n    train_list = []\n    for i in range(len(train_df)):\n        text = train_df.loc[i][text_id]\n        text = text.split(\" \")\n        text_len = text.__len__()\n        origin_text = \"\"\n        for a in text:\n            if a != \" \":\n                origin_text += (a.replace(\" \", \"\") + \" \")\n\n        one = {\n            'id': i + 1,\n            'text': origin_text,\n            'text_length': text_len,\n            'target': result_dict[train_df.loc[i][target_id]]\n        }\n        train_list.append(one)\n\n    return train_list\n\ntrain_data = get_list(corona_train)\nrandom.shuffle(train_data)\nlength = len(train_data)\ntrain_ratio, dev_ratio = 0.9, 0.1\ntrain_dataset = train_data[:int(train_ratio * length) ]\ndev_dataset = train_data[int(train_ratio * length): ]\n\nimport torch\nimport numpy\nimport pandas as pd\n\n# Define dataset\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, i):\n        text = self.dataset[i]['text']\n        label = self.dataset[i]['target']\n        return text, label\n\ntrainD = Dataset(train_dataset)\ndevD = Dataset(dev_dataset)\n\nlen(trainD), trainD[0]\na = []\nfor i in trainD:\n    a.append(len(i[0].split(\" \")))\n\nstd = numpy.std(a)\nmean = numpy.mean(a)\nmaxlen, minlen = numpy.max(a), numpy.min(a)\n\n# Print standard deviation and mean\nprint(\"Standard Deviation:\", std)\nprint(\"Mean:\", mean)\n\n# Print maximum length and minimum length\nprint(\"Maximum Length:\", maxlen)\nprint(\"Minimum Length:\", minlen)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-10T03:38:24.915864Z","iopub.execute_input":"2024-01-10T03:38:24.916241Z","iopub.status.idle":"2024-01-10T03:38:29.511280Z","shell.execute_reply.started":"2024-01-10T03:38:24.916209Z","shell.execute_reply":"2024-01-10T03:38:29.510204Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Unique values in 'Sentiment' column: ['Neutral' 'Positive' 'Negative']\nResulting dictionary: {'Neutral': 0, 'Positive': 1, 'Negative': 2}\nStandard Deviation: 11.437030662258575\nMean: 32.68024621365514\nMaximum Length: 65\nMinimum Length: 3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **BERT Tokenizer**","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\nmodel_id = \"bert-base-uncased\"\ntoken = BertTokenizer.from_pretrained(model_id)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nseq_len = 128\n\ndef collate_fn(data):\n    sents = [i[0] for i in data]\n    labels = [int(i[1]) for i in data]\n    # Encode\n    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n                                   truncation=True,\n                                   padding='max_length',\n                                   max_length=seq_len,\n                                   return_tensors='pt',\n                                   return_length=True).to(device)\n    # input_ids: encoded numbers\n    # attention_mask: is zero-padded position is 0, other position is 1\n    input_ids = data['input_ids']\n    attention_mask = data['attention_mask']\n    token_type_ids = data['token_type_ids']\n    labels = torch.LongTensor(labels)\n    return input_ids, attention_mask, token_type_ids, labels\n\n# Data loader\nloader = torch.utils.data.DataLoader(dataset=trainD,\n                                     batch_size=64,\n                                     collate_fn=collate_fn,\n                                     shuffle=True,\n                                     drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T03:38:31.794567Z","iopub.execute_input":"2024-01-10T03:38:31.794962Z","iopub.status.idle":"2024-01-10T03:38:33.586440Z","shell.execute_reply.started":"2024-01-10T03:38:31.794930Z","shell.execute_reply":"2024-01-10T03:38:33.585468Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb60d8ebde44b3ca8ada0a20394f336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9533fe3d6b2546f89fd9c9a00a8f9ba8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e103e6c0f6f457ba30196d504072055"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e0cc8242694c0f9a94210919ce21fd"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Bert-RCNN model**","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel\nfrom accelerate import Accelerator\nfrom datasets import load_metric\nimport accelerate\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score\n\nmodel_id = 'bert-base-uncased'\n\nclass TModel(torch.nn.Module):\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.pretrained = BertModel.from_pretrained(model_id)\n        self.lstm = torch.nn.LSTM(input_size=768, bidirectional=True, hidden_size=768, num_layers=1,\n                                  batch_first=False)  # LSTM model\n        self.pooling = torch.nn.MaxPool1d(kernel_size=seq_len)  # Max pooling layer\n        self.fc = torch.nn.Sequential(\n            torch.nn.Dropout(0.25),\n            torch.nn.Linear(768 * 3, num_classes),  # No for softmax function, because the cross-entropy loss function in pytorch already included softmax.\n        )\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        out = self.pretrained(input_ids=input_ids,\n                              attention_mask=attention_mask,\n                              token_type_ids=token_type_ids,\n                              output_hidden_states=False)\n        hidden_states = out[0]  # Sentence feature vector through Bert [1]\n        pooler_out = out[1] # [CLS] [2]\n        aim = hidden_states.permute(1, 0, 2) # [seq, batchsize, dim]\n        deep_mean, _ = self.lstm(aim)\n        deep_mean = deep_mean.permute(1, 0, 2)   # [batchsize, seq, dim]\n        deep_mean = deep_mean.permute(0, 2, 1)   # [batchsize, dim, seq]\n        out = self.pooling(deep_mean).squeeze(-1)\n        out = torch.cat([pooler_out, out], dim=-1)\n        out = self.fc(out)\n        return out\n\nmodel = TModel().to(device)\naccelerator = Accelerator()\naccelerate.__version__","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-10T03:39:26.485178Z","iopub.execute_input":"2024-01-10T03:39:26.486106Z","iopub.status.idle":"2024-01-10T03:39:27.108343Z","shell.execute_reply.started":"2024-01-10T03:39:26.486051Z","shell.execute_reply":"2024-01-10T03:39:27.107440Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'0.25.0'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model training and validation\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom transformers import AdamW\nfrom sklearn.metrics import f1_score, recall_score, accuracy_score\nimport torch\n\n# Set the number of epochs and configure the optimizer\nepoch = 10\noptimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\ncriterion = torch.nn.CrossEntropyLoss()\nacc_max = 0.0\nmodel_save_dir = 'saved_Corona_Bert_RCNN.pth'\n\n# Prepare the model, optimizer, and data loader for distributed training\nmodel, optimizer, loader = accelerator.prepare(model, optimizer, loader)\n\n# Create a dev data loader\nloader_dev = torch.utils.data.DataLoader(dataset=devD,\n                                          batch_size=64,\n                                          collate_fn=collate_fn,\n                                          shuffle=False,\n                                          drop_last=False)\n\n# Load the 'mrpc' metric from the 'glue' dataset\nstates = load_metric('glue', 'mrpc')\n\n# Lists to store metrics and losses during training\nepochs_list = []\naccuracies_list = []\nrecalls_list = []\nf1_list = []\ntrain_losses = []\ntest_losses = []\n\n# Training loop\nfor j in range(epoch):\n    model.train()\n    epochs_list.append(j + 1)\n    total_train_loss = 0.0\n    total_train_hits = 0\n    nums = 0\n    pre_labels = []\n    real_labels = []\n\n    # Iterate over the training data loader\n    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n        out = model(input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    token_type_ids=token_type_ids).to(device)\n\n        # Compute and backpropagate the loss\n        loss = criterion(out.to(device), labels.to(device))\n        accelerator.backward(loss)\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # Calculate training accuracy\n        out = out.argmax(dim=1)\n        hit_nums = (out.cpu() == labels.cpu()).sum().item()\n        total_train_hits += hit_nums\n\n        accuracy = hit_nums / len(labels)\n        pre_labels.extend(out.cpu().detach())\n        real_labels.extend(labels.cpu().detach())\n\n        nums += len(labels)\n        total_train_loss += loss.item()\n\n        # Print intermediate training metrics\n        # if i % 100 == 0:\n        #     print(\"No.{:} step:\".format(i))\n        #     print(i, loss.item(), accuracy)\n\n    # Calculate and print training metrics\n    cur_train_loss = total_train_loss / len(loader)\n    cur_train_acc = accuracy_score(y_true=real_labels, y_pred=pre_labels)\n    print(\"Train  loss: {:.3f} acc : {:.3f}\".format(cur_train_loss, cur_train_acc))\n    train_losses.append(cur_train_loss)\n\n    # Evaluation on the validation set\n    model.eval()\n    correct = 0\n    total = 0\n    total_loss = 0.0\n    pre_val_labels = []\n    real_val_labels = []\n    count = 0\n\n    # Iterate over the validation data loader\n    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_dev):\n        with torch.no_grad():\n            out = model(input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        token_type_ids=token_type_ids).to(device)\n            loss = criterion(out.to(device), labels.to(device))\n            count += 1\n            total_loss += loss\n\n        # Calculate validation accuracy\n        out = out.argmax(dim=1)\n        correct += (out.cpu().detach() == labels.cpu().detach()).sum().item()\n        total += len(labels)\n\n        pre_val_labels.extend(out.cpu().detach())\n        real_val_labels.extend(labels.cpu().detach())\n\n    # Calculate and print validation metrics\n    cur_dev_acc = accuracy_score(y_true=real_val_labels, y_pred=pre_val_labels)\n    cur_dev_f1 = f1_score(y_true=real_val_labels, y_pred=pre_val_labels, average='weighted')\n    cur_dev_recall = recall_score(y_true=real_val_labels, y_pred=pre_val_labels, average='weighted')\n\n    accuracies_list.append(cur_dev_acc)\n    f1_list.append(cur_dev_f1)\n    recalls_list.append(cur_dev_recall)\n\n    # Print classification report\n    cr = classification_report(y_true=real_val_labels, y_pred=pre_val_labels, digits=4)\n    print(cr)\n\n    # Update the model if validation accuracy improves\n    cur_acc = cur_dev_acc\n    if cur_acc > acc_max:\n        acc_max = cur_acc\n        print(\"Saving Model...\")\n        torch.save(model.state_dict(), model_save_dir)\n\n    avg_loss = total_loss / count\n    test_losses.append(avg_loss)\n\n    print(\"Epoch {:}  loss: {:.3f} acc : {:.3f}\".format(j + 1, avg_loss, cur_acc)) # Dev Result","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-10T03:39:29.491765Z","iopub.execute_input":"2024-01-10T03:39:29.493005Z","iopub.status.idle":"2024-01-10T05:09:13.131416Z","shell.execute_reply.started":"2024-01-10T03:39:29.492957Z","shell.execute_reply":"2024-01-10T05:09:13.130210Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233bfec17e8a4efe862fe461a4559f86"}},"metadata":{}},{"name":"stdout","text":"Train  loss: 0.466 acc : 0.825\n              precision    recall  f1-score   support\n\n           0     0.9449    0.7605    0.8427       789\n           1     0.9259    0.8857    0.9054      1793\n           2     0.8301    0.9557    0.8885      1534\n\n    accuracy                         0.8878      4116\n   macro avg     0.9003    0.8673    0.8788      4116\nweighted avg     0.8939    0.8878    0.8871      4116\n\nSaving Model...\nEpoch 1  loss: 0.324 acc : 0.888\nTrain  loss: 0.241 acc : 0.921\n              precision    recall  f1-score   support\n\n           0     0.9562    0.8023    0.8725       789\n           1     0.9176    0.9314    0.9244      1793\n           2     0.8819    0.9394    0.9097      1534\n\n    accuracy                         0.9096      4116\n   macro avg     0.9186    0.8910    0.9022      4116\nweighted avg     0.9117    0.9096    0.9090      4116\n\nSaving Model...\nEpoch 2  loss: 0.271 acc : 0.910\nTrain  loss: 0.162 acc : 0.948\n              precision    recall  f1-score   support\n\n           0     0.9725    0.8061    0.8815       789\n           1     0.9083    0.9331    0.9205      1793\n           2     0.8901    0.9400    0.9144      1534\n\n    accuracy                         0.9113      4116\n   macro avg     0.9236    0.8931    0.9055      4116\nweighted avg     0.9138    0.9113    0.9107      4116\n\nSaving Model...\nEpoch 3  loss: 0.281 acc : 0.911\nTrain  loss: 0.120 acc : 0.962\n              precision    recall  f1-score   support\n\n           0     0.9705    0.7921    0.8723       789\n           1     0.9275    0.9063    0.9168      1793\n           2     0.8547    0.9583    0.9035      1534\n\n    accuracy                         0.9038      4116\n   macro avg     0.9176    0.8856    0.8975      4116\nweighted avg     0.9086    0.9038    0.9033      4116\n\nEpoch 4  loss: 0.331 acc : 0.904\nTrain  loss: 0.092 acc : 0.970\n              precision    recall  f1-score   support\n\n           0     0.9500    0.8188    0.8795       789\n           1     0.9143    0.9219    0.9181      1793\n           2     0.8888    0.9433    0.9152      1534\n\n    accuracy                         0.9101      4116\n   macro avg     0.9177    0.8947    0.9043      4116\nweighted avg     0.9116    0.9101    0.9096      4116\n\nEpoch 5  loss: 0.357 acc : 0.910\nTrain  loss: 0.069 acc : 0.978\n              precision    recall  f1-score   support\n\n           0     0.7923    0.8657    0.8274       789\n           1     0.9099    0.9353    0.9224      1793\n           2     0.9433    0.8677    0.9039      1534\n\n    accuracy                         0.8967      4116\n   macro avg     0.8819    0.8895    0.8846      4116\nweighted avg     0.8998    0.8967    0.8973      4116\n\nEpoch 6  loss: 0.371 acc : 0.897\nTrain  loss: 0.056 acc : 0.982\n              precision    recall  f1-score   support\n\n           0     0.9514    0.7947    0.8660       789\n           1     0.8988    0.9409    0.9193      1793\n           2     0.8981    0.9250    0.9114      1534\n\n    accuracy                         0.9069      4116\n   macro avg     0.9161    0.8869    0.8989      4116\nweighted avg     0.9086    0.9069    0.9062      4116\n\nEpoch 7  loss: 0.402 acc : 0.907\nTrain  loss: 0.043 acc : 0.986\n              precision    recall  f1-score   support\n\n           0     0.9273    0.8403    0.8816       789\n           1     0.9116    0.9375    0.9244      1793\n           2     0.9120    0.9257    0.9188      1534\n\n    accuracy                         0.9145      4116\n   macro avg     0.9170    0.9012    0.9083      4116\nweighted avg     0.9148    0.9145    0.9141      4116\n\nSaving Model...\nEpoch 8  loss: 0.412 acc : 0.914\nTrain  loss: 0.034 acc : 0.989\n              precision    recall  f1-score   support\n\n           0     0.9213    0.8454    0.8817       789\n           1     0.9166    0.9253    0.9209      1793\n           2     0.8982    0.9263    0.9121      1534\n\n    accuracy                         0.9103      4116\n   macro avg     0.9120    0.8990    0.9049      4116\nweighted avg     0.9106    0.9103    0.9101      4116\n\nEpoch 9  loss: 0.468 acc : 0.910\nTrain  loss: 0.028 acc : 0.991\n              precision    recall  f1-score   support\n\n           0     0.8951    0.8327    0.8628       789\n           1     0.9370    0.8879    0.9118      1793\n           2     0.8639    0.9478    0.9039      1534\n\n    accuracy                         0.8997      4116\n   macro avg     0.8987    0.8895    0.8928      4116\nweighted avg     0.9017    0.8997    0.8995      4116\n\nEpoch 10  loss: 0.452 acc : 0.900\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\npath = \"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\"\n\ntest_df = pd.read_csv(path, encoding='latin1')\ntest_df.Sentiment.replace(to_replace='Extremely Positive', value='Positive',inplace=True)\ntest_df.Sentiment.replace(to_replace='Extremely Negative', value='Negative',inplace=True)\nprint(test_df.Sentiment.value_counts())\ncorona_test = test_df[['OriginalTweet','Sentiment']]\n\ncorona_test.OriginalTweet = corona_test.OriginalTweet.apply(process_text)\ntest_data = get_list(test_df)\ntestD = Dataset(test_data)\n\n# Testing\npre_val_labels = []  # Predicted labels list\nreal_val_labels = []  # True labels list\n\ndef test():\n    # Load the pre-trained model\n    save_path = \"./saved_Corona_Bert_RCNN.pth\"\n    model = TModel().to(device)\n    model.load_state_dict(torch.load(save_path))\n    model.eval()\n\n    # Create a data loader for the test dataset\n    loader_test = torch.utils.data.DataLoader(dataset=testD,\n                                              batch_size=1,\n                                              collate_fn=collate_fn,\n                                              shuffle=False,\n                                              drop_last=False)\n\n    correct = 0  # Counter for correct predictions\n    total = 0  # Counter for total samples\n\n    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n        with torch.no_grad():\n            out = model(input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        token_type_ids=token_type_ids).to(device)\n\n        out = out.argmax(dim=1)\n        correct += (out.cpu().detach() == labels.cpu().detach()).sum().item()\n        total += len(labels)\n        pre_val_labels.extend(out.cpu().detach())  # Extend the predicted labels list\n        real_val_labels.extend(labels.cpu().detach())  # Extend the true labels list\n\n    # Display classification report\n    cr = classification_report(y_true=real_val_labels, y_pred=pre_val_labels, digits=4)\n    print(cr)\n    \n\n# Execute the test function\ntest()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-10T05:40:10.318003Z","iopub.execute_input":"2024-01-10T05:40:10.318400Z","iopub.status.idle":"2024-01-10T05:41:23.843447Z","shell.execute_reply.started":"2024-01-10T05:40:10.318370Z","shell.execute_reply":"2024-01-10T05:41:23.842486Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Sentiment\nNegative    1633\nPositive    1546\nNeutral      619\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_42/3247737702.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  corona_test.OriginalTweet = corona_test.OriginalTweet.apply(process_text)\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.8965    0.7835    0.8362       619\n           1     0.8656    0.9334    0.8982      1546\n           2     0.9170    0.8928    0.9047      1633\n\n    accuracy                         0.8915      3798\n   macro avg     0.8930    0.8699    0.8797      3798\nweighted avg     0.8927    0.8915    0.8909      3798\n\n","output_type":"stream"}]}]}